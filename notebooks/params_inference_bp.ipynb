{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c41fd60-d06e-4b56-890d-acbcde6231a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.1, the latest is 0.5.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "from cppbridge import *\n",
    "from mcmc_analytics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "834d0f05-d771-4fba-acbf-a6ca612cfb1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4188f364-ea3c-4d41-ad53-412a04576631",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Inferring parameters with EHMM samplers for Poisson model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207a842-b540-4971-a9de-7ad3a5b83275",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The experiments are for the models and samplers presented in the paper\\\n",
    "[1] Shestopaloff A.Y, Neal R.M. Sampling Latent States for High-Dimensional Non-Linear State Space Models with the Embedded HMM Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3f4d20-905c-4feb-a220-8351f7ca7aa0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Model specification\n",
    "Here we will try to recover the parameters of the same non-linear SSM we used in the experiments with Poisson model 2 with known parameters (see `sampling_bimodal.ipynb` notebook). To do that we will specify the priors for each of the parameters driving the model: $a_i$ and $\\rho$ for transition model and $\\sigma_i$ for the observation model.\n",
    "\n",
    "Out chosen priors are as follows:\n",
    "* $a_{i}\\sim\\mathrm{U}(-1,1)$: for VAR(1) process we need our coefficients to be between -1 and 1\n",
    "* $\\rho\\sim\\mathrm{U}(0,1)$\n",
    "* $\\sigma_{i}\\sim\\mathcal{N}(0,\\sigma^{2})$\n",
    "where $\\sigma^{2}$ is a large number to make the prior vague"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af85fe36-116d-4d37-82a5-7bf43fe65fde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the transition model with unknown parameters\n",
    "T = 250\n",
    "n = 10\n",
    "A = DiagonalMatrixParam()\n",
    "aa = -1.\n",
    "bb = 1.\n",
    "A.parametrize(n, DistributionType.UNIFORM, (aa, bb), minx=aa, maxx=bb)\n",
    "Q = SymmetricMatrixParam()\n",
    "a = 0.\n",
    "b = 1.\n",
    "x_var = 1.\n",
    "Q.parametrize(n, DistributionType.UNIFORM, (a, b), x_var, minx=a, maxx=b)\n",
    "# Prior mean is always zero\n",
    "prior_mean = np.zeros(n)\n",
    "# The prior covariance will be re-calculated for each newly accepted parameters, including for the first iteration \n",
    "# so below will not be used but still required to intialize the class \n",
    "Q_init = np.eye(n)\n",
    "trm = TransitionSpec(A, Q, prior_mean, Q_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d67aa0-6467-4e0e-bed8-854b424841d4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the observation model with unknown parameters\n",
    "sigma = VectorParam()\n",
    "mu = 0\n",
    "var = 25\n",
    "sigma.parametrize(n, DistributionType.NORMAL, (mu, np.sqrt(var)))\n",
    "obsm = ObservationSpec(ModelType.BIMODAL_POISSON, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7e0a8-508b-4863-97ba-e081f380730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also specify the true values of parameters:\n",
    "params_names = [\"$a_i$\", \"$\\\\rho$\", \"$\\sigma_i$\"]\n",
    "true_values = dict(zip(params_names, [0.9, 0.7, 0.8]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc23579-126c-4e81-9b7f-28d2653d48b7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sampler specification\n",
    "### Embedded HMM sampling scheme\n",
    "In these experiments we will only be using EHMM sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a58cdf85",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Specify EHMM scheme\n",
    "nupd = 50  # number of parameter updates between the scheme runs\n",
    "pool_sz = 80\n",
    "ehmm_sampler = SamplerSpec(SamplerType.EHMM, pool_size=pool_sz, num_parameter_updates=nupd, flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c40802",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Observations\n",
    "We need the observations, on which to run the samplers. The data we use is the synthetic data, generated in `models.ipynb` notebook. In this experiemtns we will try and recover the parameters used to generate that data as well as the latent states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405e6801",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = \"gauss_poiss2_3225125971228064704\"\n",
    "dataprovider = model + \"_data.h5\"\n",
    "dataspec = Data(dataprovider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e5ab9-9597-4f03-9af7-71f26e3ebfd6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Simulation    \n",
    "To run the simulation we need to provide the initial sample $\\mathbf{x}_0$ to start off the sampler, and specify the parameters of the simulation. As in the case when we ran the model with known parameters, here we also set $\\mathbf{x}_0=\\mathbf{1}$ and run 5 simulations for $10 000$ iterations each, starting with the different seed for randomisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f80918-668d-4c8c-9882-37028b5ca924",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_iter_ehmm = 10000\n",
    "x_init = np.ones((n, T))\n",
    "seeds = np.array([1, 10, 100, 1e4, 1e5], dtype=int)\n",
    "scales_ehmm = np.array([0.05, 0.2])\n",
    "reverse = False\n",
    "flip = True\n",
    "simulation_ehmm = SimulationSpec(n_iter_ehmm, seeds, x_init, scaling=scales_ehmm, reverse=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a27e0-b66a-4b8d-bef7-5284b92a1934",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Simulation with EHMM sampler\n",
    "ehmm_session_name = f\"param_ehmm80_flip_{model}\"\n",
    "mcmc_ehmm_bp = MCMCsession(ehmm_session_name)\n",
    "if mcmc_ehmm_bp.hasResults():\n",
    "    mcmc_ehmm_bp.loadResults()\n",
    "else:\n",
    "    mcmc_ehmm_bp.init(T, trm, obsm, ehmm_sampler, simulation_ehmm, dataspec)\n",
    "    mcmc_ehmm_bp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f0b960",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Analysis of the results\n",
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e887b-db03-450e-951b-54ec7c3bc788",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ehmm_burnin = int(0.1 * 2 * (n_iter_ehmm + 1))  # <-- as we run on reversed sequence, too, there will be twice as many samples\n",
    "ehmm_samples = mcmc_ehmm_bp.getSamples(ehmm_burnin)\n",
    "psamples = mcmc_ehmm_bp.getParamSamples(ehmm_burnin, params_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28d766-160e-49ff-a412-2d894dca8fad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ac_ehmm = getACF(mcmc_ehmm_bp.samples, ehmm_samples)\n",
    "taus_ehmm = 1 + 2 * np.sum(ac_ehmm, axis=2)\n",
    "meantaus_ehmm = np.mean(taus_ehmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13dcc1-e0ed-4a90-97cd-264698beca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpsamples = {k:v[:,np.newaxis] for k, v in mcmc_ehmm_bp.param_samples.items()}\n",
    "ac_params = getACF(allpsamples, psamples.values[:,np.newaxis], lags=1000)\n",
    "taus_params = 1 + 2 * np.sum(ac_params, axis=2)\n",
    "meantaus_params = np.mean(taus_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4188cf8-78f2-42bc-a056-44c26dd2dd31",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ehmm_met_acc = 100 * np.mean(\n",
    "    [acc[:T].mean() / (n_iter_ehmm * pool_sz * (1 + reverse)) for _, acc in mcmc_ehmm_bp.acceptances.items()])\n",
    "ehmm_shift_acc = 100 * np.mean(\n",
    "    [acc[T + 1:].mean() / (n_iter_ehmm * pool_sz * (1 + reverse)) for _, acc in mcmc_ehmm_bp.acceptances.items()])\n",
    "ehmm_partrm_acc = 100 * np.mean([acc['trm'] / (n_iter_ehmm * nupd * (1 + reverse)) for _, acc in mcmc_ehmm_bp.param_acceptances.items()])\n",
    "ehmm_parobm_acc = 100 * np.mean([acc['obsm'] / (n_iter_ehmm * nupd * (1 + reverse)) for _, acc in mcmc_ehmm_bp.param_acceptances.items()])\n",
    "ehmm_overview = {\"Num seeds\": len(seeds),\n",
    "                 \"Num iter\": n_iter_ehmm,\n",
    "                 \"Time per sample, ms\": np.mean(list(mcmc_ehmm_bp.durations.values())) /\n",
    "                                        list(mcmc_ehmm_bp.samples.values())[0].shape[0],\n",
    "                 \"Acceptance rate, autoregressive update, %\": ehmm_met_acc,\n",
    "                 \"Acceptance rate, shift update, %\": ehmm_shift_acc,\n",
    "                 \"Acceptance rate, param updates for transition model, %\": ehmm_partrm_acc,\n",
    "                 \"Acceptance rate, param updates for observation model, %\": ehmm_parobm_acc,\n",
    "                 \"Average autocorrelation time, states\": meantaus_ehmm,\n",
    "                 \"Average autocorrelation time, params\": meantaus_params\n",
    "                 }\n",
    "overview = pd.DataFrame({\"EHMM on Poisson model 2\": ehmm_overview})\n",
    "overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121fd0f7-8601-45be-8e52-3d2f85ff75cb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ehmm_ar = np.stack(list(mcmc_ehmm_bp.acceptances.values()), axis=1)[:T].ravel() / (\n",
    "            n_iter_ehmm * pool_sz * (1 + reverse))\n",
    "ehmm_shift = np.stack(list(mcmc_ehmm_bp.acceptances.values()), axis=1)[T + 1:].ravel() / (\n",
    "            n_iter_ehmm * pool_sz * (1 + reverse))\n",
    "pd.DataFrame(dict(ehmm_ar=ehmm_ar, ehmm_shift=np.append(ehmm_shift, [np.nan] * len(seeds)))).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946d04",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test equality of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4949d9af",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params_ttest = ttest(psamples, list(true_values.values()))\n",
    "pd.DataFrame({\"p-value\":params_ttest}, index=params_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0119ef-a561-4140-b6f7-d727efdef5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"means\":psamples.mean(axis=0), \"variances\": psamples.var(axis=0)}, index=params_names).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa05e5f-5f9f-48dd-8864-d8028298fe5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for pname in params_names:\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    ax.hist(psamples[pname], bins=50, density=True)\n",
    "    ax.vlines(true_values[pname], 0, 1, transform=ax.get_xaxis_transform(), linestyles='dashed', color=\"C2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790b6631-5441-4c17-b65d-ac2dca81030f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Convergence analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df8e9e-6622-478f-9966-ac1e23a45ce4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epsr = getEPSR(mcmc_ehmm_bp.samples, ehmm_burnin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c49f7e-1d69-487c-ab90-a500b9d39454",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "xs = np.array(range(1, T+1))\n",
    "for i in range(n):\n",
    "    ax.plot(xs, epsr[:, i])\n",
    "ax.set_xmargin(0.01)\n",
    "ax.locator_params(axis='y', nbins=10)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "# for i, tick in enumerate(ax.yaxis.get_ticklabels()):\n",
    "#     if i % 2 != 0:\n",
    "#         tick.set_visible(False) \n",
    "plt.tight_layout()\n",
    "# plt.savefig(OUTPUTS_PATH/\"epsr_met_lp.png\", dpi=300, format='png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e545c83-f876-4393-880e-49dca3011041",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Autocorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8041a4-51b5-49e0-b05c-202e806dd624",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "xs = np.array(range(1, T+1))\n",
    "for i in range(n):\n",
    "    ax.plot(xs, taus_ehmm[i, :]*overview.loc['Time per sample, ms', 'EHMM on Poisson model 2'])\n",
    "ax.set_xmargin(0.01)\n",
    "ax.set_xlabel(\"time $t$\")\n",
    "ax.set_ylabel(\"autocorrelation time, ms\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(OUTPUTS_PATH/\"taus_ehmm_lp.png\", dpi=300, format='png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36c736-bf23-4641-85ea-225a6f2ac30f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "d = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb0b6f-4c06-4f89-ad7a-1b9be474aca8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "plotACF(ac_ehmm, t, d, ax)\n",
    "ax.set_ylim(-0.25,1)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(OUTPUTS_PATH/f\"acf_ehmm_{t}-{d}_lp.png\", dpi=300, format='png')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd3f809-fa2d-4746-a3af-483763b44f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "for idx, param_name in enumerate(params_names):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    for seed in seeds:\n",
    "        data = mcmc_ehmm_bp.getParamSamples(0, params_names, forseed=seed)\n",
    "        plot_acf(data[param_name], ax, lags=1000, adjusted=True, fft=True, alpha=None, title=f\"Autocorrelaiton for {param_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e708c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Trace plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bbc877",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotTrace(ehmm_samples, t, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097fb938-14b9-4f9c-afcd-922c98f848f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotMixing(mcmc_ehmm_bp.samples, t, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1116a597-8b56-4881-9563-999e9f782369",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for idx, param_name in enumerate(params_names):\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "    for seed in seeds:\n",
    "        data = mcmc_ehmm_bp.getParamSamples(0, params_names, forseed=seed)\n",
    "        ax.plot(data.index, data[param_name], label=f\"seed {seed}\")\n",
    "\n",
    "    ax.set_xmargin(0.01)\n",
    "    ax.set_ylabel(param_name)\n",
    "    ax.set_xlabel(\"sample index\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(OUTPUTS_PATH / f\"param_plotmix_{param_name}.png\", dpi=300, format='png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d468a-2fa0-4a62-8172-31c6566222a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparison of tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf230bdc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadict = defaultdict(dict)\n",
    "for item in DATA_PATH.iterdir():\n",
    "    fn = str(item).split(\"/\")[-1]\n",
    "    if fn.startswith(\"paramtest\"):\n",
    "        spec = \"-\".join(fn.split(\"_\")[1:5])\n",
    "        if fn.endswith('specs.h5'):\n",
    "            coldict = {}\n",
    "            with h5py.File(item, 'r') as f: \n",
    "                coldict[('model','A mean')] = f['model/transition/A'][4:6].mean()\n",
    "                coldict[('model','A var')] = (f['model/transition/A'][5] - f['model/transition/A'][4])**2 / 12\n",
    "                coldict[('model','A varscale')] = f['model/transition/A'][3]\n",
    "                coldict[('model','Q mean')] = f['model/transition/Q'][4:6].mean()\n",
    "                coldict[('model','Q var')] = (f['model/transition/Q'][5] - f['model/transition/Q'][4])**2 / 12\n",
    "                coldict[('model','Q varscale')] = f['model/transition/Q'][3]\n",
    "                coldict[('model','C mean')] = f['model/observation/C'][4]\n",
    "                coldict[('model','C var')] = f['model/observation/C'][5]**2\n",
    "                coldict[('model','C varscale')] = f['model/observation/C'][3]\n",
    "                coldict[('model','D mean')] = f['model/observation/D'][4]\n",
    "                coldict[('model','D var')] = f['model/observation/D'][5]**2\n",
    "                coldict[('model','D varscale')] = f['model/observation/D'][3]\n",
    "                coldict[('sampler', 'npu')] = f['sampler'].attrs['num_param_updates']\n",
    "                coldict[('sampler', 'scaling')] = f['simulation/scaling'][2:]\n",
    "            datadict[spec].update(coldict)\n",
    "        else:\n",
    "            coldict = {}\n",
    "            with h5py.File(item, 'r') as f:\n",
    "                mcmc_name = \"_\".join(fn.split(\"_\")[:-2])\n",
    "                mcmc = MCMCsession(mcmc_name)\n",
    "                mcmc.loadResults()\n",
    "                rev = not (\"noreverse\" in fn)\n",
    "                burnin = int(0.1 * (1 + rev) * (n_iter_ehmm + 1))\n",
    "                samples = mcmc.getSamples(burnin)\n",
    "                psamples = mcmc.getParamSamples(burnin, params_names)\n",
    "                allpsamples = {k:v[:,np.newaxis] for k, v in mcmc.param_samples.items()}\n",
    "                ac_params = getACF(allpsamples, psamples.values[:,np.newaxis], lags=1000)\n",
    "                taus_params = 1 + 2 * np.sum(ac_params, axis=2)\n",
    "                meantaus_params = np.mean(taus_params)\n",
    "                coldict = {(\"params\", f\"{pn} mean\"): pv for pn, pv in psamples.mean(axis=0).to_dict().items()}\n",
    "                coldict.update({(\"params\", f\"{pn} var\"): pv for pn, pv in psamples.var(axis=0).to_dict().items()})\n",
    "                coldict.update({(\"params\", f\"{pn} HDR\"): np.array([f\"({x[0]:.2f},{x[1]:.2f})\" \n",
    "                                                                   for x in getHDR(ps, bins=1000, kde=True)]).squeeze()\n",
    "                                for pn, ps in psamples.items()})\n",
    "                coldict.update({(\"params\", \"trm acc\"): acc['trm'] for _, acc in mcmc.param_acceptances.items()})\n",
    "                coldict.update({(\"params\", \"obm acc\"): acc['obsm'] for _, acc in mcmc.param_acceptances.items()})\n",
    "                coldict.update({(\"params\", \"mean ACT\"): meantaus_params})\n",
    "                coldict.update({(\"states\",\"$x_{0,0}$ mean\"): samples[:,0,0].mean(), (\"states\",\"$x_{0,0}$ std\"): samples[:,0,0].std()})\n",
    "            datadict[spec].update(coldict)\n",
    "df = pd.DataFrame.from_dict(datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ee1f6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def inHDR(hdr, val):\n",
    "    hdr = [float(v) for v in hdr[1:-1].split(\",\")]\n",
    "    lo, hi = np.min(np.abs(hdr)), np.max(np.abs(hdr))\n",
    "    return lo <= abs(val) <= hi\n",
    "\n",
    "delete = []\n",
    "for en, er in df.items():\n",
    "    for pn in params_names:\n",
    "        hdr = er.loc[('params', f'{pn} HDR')]\n",
    "        notin = True\n",
    "        if hdr.size > 1:\n",
    "            notin = reduce(lambda x, y: not x and not y, [inHDR(intrvl, true_values[pn]) for intrvl in hdr], notin)\n",
    "        else:\n",
    "            notin &= not inHDR(str(hdr), true_values[pn])\n",
    "        if notin:\n",
    "            print(f\"Delete {en} due to {pn} out of HDR\")\n",
    "            delete.append(en)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c804c60f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(delete, axis=1).sort_values(('params','mean ACT'), axis=1, ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede93673-addb-497e-8cfd-5d8226012e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
